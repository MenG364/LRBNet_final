import mathimport osimport timeimport torchimport torch.nn as nnimport torch.nn.functional as Ffrom torch.autograd import Variablefrom tqdm import tqdmimport numpy as npimport utilsfrom ReGAT_models.position_emb import prepare_graph_variablesfrom metrics import Metrics, accumulate_metrics, TBXfrom train import instance_bce_with_logits, compute_score_with_ensemblefrom vqa_utils import VqaUtils, PerTypeMetricdef compute_score_with_logits(logits, labels, device):    # argmax    logits = torch.max(logits, 1)[1].data    logits = logits.view(-1, 1)    one_hots = torch.zeros(*labels.size()).to(device)    one_hots.scatter_(1, logits, 1)    scores = (one_hots * labels)    return scores@torch.no_grad()def test_with_no_answer(model, dataloader, args, device):    model.eval()    relation_type = dataloader.dataset.relation_type    all_preds = []    with tqdm(total=len(dataloader), ncols=120) as pbar:        for i, (v, norm_bb, q, cap, question_types,                question_ids, image_id, bb) in enumerate(dataloader):            num_objects = v.size(1)            v = Variable(v).to(device)            norm_bb = Variable(norm_bb).to(device)            q = Variable(q).to(device)            cap = Variable(cap).to(device)            sem_adj_matrix, spa_adj_matrix = None, None            pos_emb_L, sem_adj_matrix_L, spa_adj_matrix_L = prepare_graph_variables(                relation_type, bb, sem_adj_matrix, spa_adj_matrix, num_objects,                args.nongt_dim, args.imp_pos_emb_dim, args.spa_label_num,                args.sem_label_num, device)            pos_emb_R, sem_adj_matrix_R, spa_adj_matrix_R = pos_emb_L, sem_adj_matrix_L, spa_adj_matrix_L            # pred, att = model(v, t2i, cap, norm_bb, q)            pred = model(v, cap, norm_bb, q, pos_emb_L, pos_emb_R,                         sem_adj_matrix_L, sem_adj_matrix_R,                         spa_adj_matrix_L, spa_adj_matrix_R)            joint_logits, cap_logits, v_logits = pred['logits']            joint_soft = F.softmax(joint_logits, -1)            cap_soft = F.softmax(cap_logits, -1)            v_soft = F.softmax(v_logits, -1)            pred = (joint_soft + cap_soft + v_soft) / 3            pred_ans_ixs = pred.max(1)[1]            for curr_ix, pred_ans_ix in enumerate(pred_ans_ixs):                pred_ans = dataloader.dataset.label2ans[int(pred_ans_ix)]                all_preds.append({                    'question_id': str(question_ids[curr_ix]),                    'answer': str(pred_ans)                })            pbar.update()    return all_predsdef test(model, test_loader, args, device=torch.device("cuda")):    if args.checkpoint != "":        print("Loading weights from %s" % (args.checkpoint))        if not os.path.exists(args.checkpoint):            raise ValueError("No such checkpoint exists!")        checkpoint = torch.load(args.checkpoint)        state_dict = checkpoint.get('model_state_dict', checkpoint)        model.load_state_dict(state_dict)    all_preds = test_with_no_answer(model, test_loader, args, device)    VqaUtils.save_preds(all_preds, args.expt_save_dir, args.test_split, 0)