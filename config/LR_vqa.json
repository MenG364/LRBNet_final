{
    "epochs": 25,
    "base_lr": 0.01,
    "lr_decay_start": 15,
    "lr_decay_rate": 0.25,
    "lr_decay_step": 2,
    "lr_decay_based_on_val": true,
    "grad_accu_steps": 1,
    "grad_clip": 0.25,
    "weight_decay": 0.0001,
    "batch_size": 128,
    "output": "saved_models/",
    "log_interval": -1,
    "dataset": "vqa",
    "data_folder": "/fengjf_phd/LiuRG/LRGNN/VQA2.0",
    "val_yaml": "val_more_than_0.5.yaml",
    "train_yaml": "train_more_than_0.5.yaml",
    "use_both": false,
    "use_vg": false,
    "adaptive": true,
    "relation_type": "implicit",
    "fusion": "LR",
    "tfidf": true,
    "op": "c",
    "num_hid": 1024,
    "ban_gamma": 8,
    "num_heads": 16,
    "imp_pos_emb_dim": 64,
    "dir_num": 2,
    "spa_label_num": 11,
    "sem_label_num": 15,
    "relation_dim": 1024,
    "nongt_dim": 20,
    "num_steps": 1,
    "residual_connection": true,
    "label_bias": false,
    "expt_name": "VQA",
    "num_layer": 1,
    "fusion_num_layer": 1,
    "apply_rubi": true,
    "pretrain_model": "saved_models/LRBNet_implicit/ban_1_implicit_vqa_314/model_20.pth"

}
